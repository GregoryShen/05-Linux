#### 10.2 Shell的变量功能

##### 10.2.3 环境变量的功能

可以用env 和 export 来查看当前shell 环境汇中的默认环境变量

###### 用env观察环境变量与常见环境变量说明

**PATH**: 可执行文件的搜索路径，目录与目录中间以冒号（:）分隔，由于文件的搜索是依序PATH的变量内的目录来查询的，所以，**目录的顺序也是重要的**

**RANDOM**：随机变量，目前大多数的distribution都有随机数生成器，那就是/dev/random 这个文件。我们可以通过这个随机数文件相关的变量（$RANDOM）来随机取得随机数值。在BASH 环境下，这个RANDOM变量的内容介于0~32767之间，所以，只要echo \$RANDOM时，系统就会主动的随机取出一个介于0~32767之间的数值。如果想使用0~9 之间的数值，用declare声明数值类型，然后按下面做就可以了

:star:

```shell
declare -i number=$RANDOM*10/32768 ; echo $number
 <== 此时会随机取出0~9 之间的数值
```

###### 用set观察所有变量（含环境变量与自定义变量）

bash除了环境变量，还有一些**与bash操作界面有关的变量**，以及使用者自己定义的变量存在。一般来说，不论是否为环境变量，只要跟我们目前这个shell的操作界面有关的变量，通常都会被设定为大写字符。也就是说，**基本上，在linux默认的情况中，使用{大写的字母}来设定的变量一般为系统内定需要的变量**。

可以利用set 来查看命令提示字符的设定，PS1。'[\u@\h \W]\$'

反斜线的数据为PS1的特殊功能，跟bash的变量设定没有关系。

* **$：（关于本shell的PID）**

  钱字本身也是个变量，他代表的是目前这个shell的执行编号，就是shell的PID。想要知道我们shell的PID，就可以用echo $$，出现的数字就是你的PID

* **?：（关于上个执行指令的回传值）**

  当我们执行某些指令时，这些指令都会回传一个执行后的代码，一般来说，如果成功执行该指令，则会回传一个0，如果执行过程中发生错误，就会回传错误代码，一般是以非0的数值来取代

  ```shell
  $ echo $SHELL
  /bin/bash		<== 可以顺利显示，没有错误
  $ echo $?
  0				<== 因为没有问题，所以回传值为0
  $ 12name=VBird
  bash: 12name=VBird: command not found...	<==发生错误了！bash 回报有问题
  $ echo $?
  127				<== 因为有问题，回传错误代码（非0）
  $ echo $?
  0				# 因为上一个指令执行的是echo $?，当然没有错误，所以是0没错
  ```

* **OSTYPE,HOSTTYPE, MACHTYPE:(主机硬件与核心的等级)**

###### export：自定义变量转成环境变量

环境变量与自定义变量的差异在于：**该变量是否可以被子进程所继续引用**

**子进程仅会集成父进程的环境变量，子进程不会集成父进程的自定义变量。**

如果可以把自定义变量变成环境变量，就可以让该变量继续在子进程中使用。

export 变量名称

如果仅下达export而没有接变量时，那么会把所有的环境变量show出来

##### 10.2.6 变量键盘读取、阵列与声明：read,array, declare

###### read

```shell
$ read [-pt] variable
选项与参数：
-p：后面可接提示字符
-t：后面可接等待的秒数，这个比较又去，不会一直等待使用者
```

范例一：让使用者由键盘输入一内容，将该内容变成名为atest的变量

```shell
$ read atest
#此时游标会等待你的输入
$ echo ${atest}
```

​:star: 范例二：提示使用者30 秒内输入自己的名字，将该输入字符串作为名为named 的变量内容

```shell
$ read -p "Please input your name:" -t 30 named
Vbird Tsai
$ echo ${named}
```

read 之后不加任何参数，直接加上变量名称，那么底下就会主动出现一个空白行等待你的输入。如果加上-t后面接秒数，超过秒数后该指令就会自动略过。如果加上-p在输入的游标前就会有比较多可以用的提示字符给我们参考。

###### declare/typeset

declare或typeset 是一样的功能， 就是在声明变量的类型。如果使用declare 后面没接任何参数，那么bash就会主动的将所有的变量名称与内容通通调用出来。

```shell
$ declare [-aixr] variable
-a：将后面名为variable的变量定义为array类型
-i：将后面名为variable的变量定义为整型
-x：用法与export一样，将后面的variable变成环境变量
-r：将变量设定为readonly类型，不可被更改内容，也不能unset
```

* 变量类型默认为字符串，如果不指定变量类型，则1+2为一个字符串而不是计算式。
* bash环境中的数值运算，默认最多仅能到整数形态，所以1/3结果是0

所以如果需要非字符串类型的变量，那就得要进行变量的声明才行

###### 数组变量类型：array

在bash里，数组的设定方式是：

```shell
var[index] = content
```

意思是，我有一个阵列名称为var，内容为var[1]=小明 等等。目前bash提供的是一维数组。

##### 10.2.7 与文件系统及进程的限制关系:ulimit

bash是可以限制使用者的某些资源的，包括可以开启的文件数量，可以使用的CPU时间，可以使用的主存总量等等。

```shell
$ ulimit [-SHacdfltu] [配额]
选项与参数：
-H：hard limit，严格的设定，必定不能超过这个配置的数值
-S：soft limit，警告的设定，可以超过这个设定值，但是如果超过则有警告信息
    在设定上，通常soft会比hard小，举例来说，soft可设定为80而hard设定为100，那么你可以使用到90，但是介于     80~100之间时，系统会有警告信息通知你
-a：后面不接任何选项与参数，可列出所有的限制额度
-c：当某些程序发生错误时，系统可能会将该程序在主存中的信息写成文件（debug用），这种文件就被称为核心文件（core file），此为限制每个核心文件的最大容量
-f：此shell可以建立的最大文件容量（一般可能设定为 2GB），单位为Kbyte
-d：进程可使用的最大segment主存容量
-l：可用于锁定（lock）的主存量
-t：可使用的最大CPU时间（单位为秒）
-u：单一使用者可以使用的最大进程数量
```

​:star: 范例一：列出你目前身份（假设为一般账号）的所有限制资料数值

```shell
$ ulimit -a
core file size 			(blocks, -c) 0	<== 只要是0就代表没限制
data seg size			(Kbytes, -d) unlimited
scheduling priority				(-e) 0
file size				(blocks, -f) unlimited	<== 可建立的单一文件大小
open files						(-n) 1024 <== 可同时开启的文件数量
...
```

​:star: 范例二：限制使用者仅能建立 10MBytes 以下容量的文件

```shell
$ ulimit -f 10240
$ ulimit -a | grep 'file size'

# 然后尝试去建立20MB的文件
$ dd if=/dev/zero of=123 bs=1M count=20
File size limit exceeded (core dumped)

$ rm 123
# 将这个文件删除，同时要登出再登入才能解开10M的限制
```

我们在磁盘文件系统中提过，单一文件系统能够支持的单一文件大小与block的大小有关。但是文件系统的限制容量都允许的太大了，如果想要让使用者建立的文件不要太大时，我们是可以考虑用ulimit来限制使用者可以建立的文件大小。利用ulimit -f 就可以设置了。但是要注意单位是Kbytes。

想要复原ulimit的设定的最简单的方法就是登出再登入，否则就得要重新以ulimit设定才行。要注意的是，一般身份使用者如果以ulimit设定了-f 的文件大小，那么他只能继续减少文件容量，不能增加文件容量。另外，如果想要管控使用者的ulimit限值，可以参考pam的介绍。

##### 10.2.8 变量内容的删除、取代与替换

###### 变量内容的删除与取代

格式

```shell
echo ${要进行修改的变量名称#/%（#代表从最左边开始且仅删除最短的那个
                              ##代表从最左边开始且符合要求的最长的那个
                              %代表从最右边开始且仅删除最短的那个
                              %%代表从最右边开始切符合要求的最长的那个
                              ）要被删除的部分}
```

范例：假设你是dmtsai，那你的MAIL变量应该是/var/spool/mail/dmtsai,假设只想要保留最后的文件名（dmtsai），前面的目录名称都不要了，如何利用$MAIL变量来达成

```shell\
echo {MAIL##/*/}
```

范例六：将path的变量内容内的sbin 取代成大写SBIN

```shell
echo ${path/sbin/SBIN}
```

如果是两条斜线，那就变成所有符合的内容都会被取代

```shell
echo ${path//sbin/SBIN}
```

###### 变量的测试与内容替换

在某些时刻我们需要判断某个变量是否存在，如果存在则使用既有的设定，如果不存在则给予一个常用的设定。

范例一：测试一下是否存在username这个变量，如果不存在则给予username内容为root

```shell
$ echo ${username}
		<==由于出现空白，所以username可能不存在，也可能是空白字符串
$ username=${username-root}
$ echo ${username}
root    <== 因为username 没有设定，所以主动给予名为root的内容
$ username="vbird tsai"   <== 主动设定username的内容
$ username=${username-root}
$ echo ${username}
vbird tsai <== 因为username已经设定了，所以使用旧有的设定而不以root取代
```

在上面的范例中，重点在于减号[-]后面接的关键字，基本上可以这样理解

```shell
new_var=${old_var-content}
new_var # 新的变量，主要用来取代旧变量，新旧变量的名称通常一样
```

范例二：如果username 未设定或为空字符串，则将username 内容设定为root

```shell
$ useranme=""
$ username=${useranme-root}
$ echo ${username}
		<== 因为username被设定为空字符串了，所以当然还是保留为空字符串
$ username=${useranme:-root}
$ echo ${username}
$ root	<== 加上：如果变量内容为空或是未设定，都能够以后面的内容替换
```

在大括号内有没有冒号：的差别是很大的，加上冒号后，被测的变量未被设定或者是已被设定为空字符串时，都能够用后面的内容来替换与设定，

#### 10.5 数据流重导向

数据流重导向就是将某个指令执行后应该要出现在屏幕上的数据，给传输到到其他地方，例如文件或者是设备（例如打印机之类），这个东西在Linux的文字模式下很重要，尤其是如果我们想要将某些数据存储下来时

##### 10.5.1 什么是数据流重导向

我们执行一个指令的时候，这个指令可能会由文件读入数据，经过处理之后，再将数据输出到屏幕上。标准输出与标准错误输出默认都是输出到屏幕上面来的

标准输出指的是”指令执行所回传的正确的信息“，标准错误可以理解为”指令执行失败后，所回传的错误信息“。比如，我们系统默认有  /etc/crontab 但却没有 /etc/vbirdsay， 此时若下达 cat /etc/crontab /etc/vbridsay 这个指令时，cat会进行：

标准输出：读取 /etc/crontab 后，将该文件内容显示到屏幕上

标准错误输出：因为无法找到 /etc/vbirdsay， 因此在屏幕上显示错误讯息

不管正确或错误的数据都是默认输出到屏幕上，所以屏幕是乱乱的。

__标准输入：代码为0，使用< 或 <<__

__标准输出：代码为1，使用 > 或 >>__

__标准错误输出：代码为2，使用 2> 或 2>>__

范例一：观察你的系统根目录（/）下各目录的文件名、权限与属性，并记录下来

```shell
$ ll /  #此时屏幕会显示出文件名
$ ll / > ~/rootfile #屏幕并无任何信息
$ ll ~/rootfile # 有个新文件被建立了
```

如果再次下达 ll /home > ~/rootfile，它将变成仅有 ll /home 的资料，而原本的ll / 就没有了

因为该文件的建立方式是：

1. 该文件（本例中是~/rootfile)若不存在，系统会自动的将他建立起来，但是
2. 当这个文件存在的时候，那么系统就会先将这个文件内容清空，然后再将数据写入
3. 也就是如果以>输出到一个已存在的文件中，那个文件会被覆盖掉

如果想要将数据累加而不将旧的数据删除，那么就利用两个大于符号就好了。以上面的范例阿狸说，应该要改成 ll / >> ~/rootfile 即可。

范例二：利用一般身份账号搜寻 /home 底下是否有名为 .bashrc 的文件存在

```shell
$ find /home -name .bashrc
find: ;;;;;;
```

由于/home 底下还有我们之前建立的账号存在，所以不可以都看到。所以就会有错误及正确资料了。假如我想要将数据输出到list这个文件中呢，执行 find /home -name .bashrc > list, 会发现list里面仅仅存储了正确输出信息，至于屏幕上还是会有错误的信息出现。如果要将正确与错误的信息分别存入不同的文件中需要怎么做？

:star: 范例三：承范例二，将stdout 与stderr 分别存到不同文件中去

```shell
$ find /home -name .bashrc > list_right 2> list_error
```

###### /dev/null 垃圾桶黑洞设备与特殊写法

如果我知道错误信息会发生，所以要将错误信息忽略掉而不显示或储存呢，这时候黑洞装置 /dev/null 就很重要了，这个/dev/null 可以吃掉任何导向这个设备的信息

范例四：承接范例三，将错误的信息丢弃，屏幕上显示正确的资料

```shell
$ find /home -name .bashrc 2> /dev/null  #只有stdout 会显示到屏幕上，stderr被丢弃了
```

再想想一下，如果我要将正确与错误信息通通写入同一个文件去呢，这个时候就要使用特殊的写法了

:star: 范例五：将指令的资料全部写入名为list 的文件中

```shell
$ find /home -name .bashrc > list 2> list #这是错误的写法
$ find /home -name .bashrc > list 2>&1   #正确的写法
$ find /home -name .bashrc &> list   # 正确的写法
```

第一行错误的原因是：__由于两股数据同时写入一个文件，有没有使用特殊的语法，此时两股数据可能会交叉写入该文件内，造成次序的错乱__, 所以虽然最终list文件还是会产生，但是里面的数据排列就会怪怪的，而不是原本屏幕上的输出排序

###### standard input：< 与 <<

范例六：利用cat 指令来建立一个文件的简单流程

```shell
$ cat > catfile
testing
cat file test
<== 这里按下ctrl+d来离开
```

由于加入> 在cat后，所以那个catfile会被主动的建立，而内容就是刚刚键盘输入的那两行资料

范例七：用stdin 取代键盘的输入以建立新文件的简单流程

```shell
$ cat > catfile < ~/.bashrc
$ ll catfile ~/.bashrc
```

<<代表结束的输入字符的意思，举例：我要用cat 直接将输入的信息输出到catfile中，且当由键盘输入eof时，该次输入就结束。

```shell
$ cat > catfile << "eof"
> this is a test.
> ok now stop
> eof
```

利用<< 右侧的字符，我们可以终止一次输入，而不必输入[ctrl]+d来结束。

为什么要使用命令输出重导向：

- 屏幕输出的信息很重要，而且我们需要将他存下来的时候
- 背景执行中的程序，不希望他干扰屏幕正常的输出结果时
- 一些系统的例行命令（例如写在/etc/crontab 中的文件）的执行结果，希望他可以存下来时
- 一些执行命令的可能已知错误讯息时，想以 2> /dev/null 将他丢掉时
- 错误信息与正确信息需要分开输出时

问，假设我要将 echo "error message" 以standard error output 的格式来输出，该如何处置？

答：既然有 2>&1 来将 2>转到 1>去，那应该也会有 1>&2吧

```shell
$ echo "error message" 1>&2
$ echo "error message" 2> /dev/null 1>&2
```

结果是第一条有信息输出到屏幕上，第二条没有信息，这表示该信息已经通过2> /dev/null 丢到垃圾桶去了，可以肯定是错误讯息

##### 10.5.2 命令执行的判断依据：;,&&,||

###### $?(指令回传值) 与 && 或 ||

__如果前一个指令执行的结果为正确，在Linux下会回传一个$?=0的值__

| 指令下达情况         |                 说明                 |
| :------------- | :--------------------------------: |
| cmd1 && cmd2   | 1. 若cmd1执行完毕且正确执行（$?=0）,则开始执行cmd2  |
|                |  2. 若cmd1执行完毕且为错误（$?!=0）,则cmd2不执行  |
| cmd1 \|\| cmd2 | 1. 若cmd1 执行完毕且正确执行（$?=0），则cmd2 不执行 |
|                |  2. 若cmd1执行完且为错误（$?!=0）,则开始执行cmd2  |

范例一：使用ls 查阅目录 /tmp/abc 是否存在，若存在则用 touch 建立 /tmp/abc/hehe

```shell
$ ls /tmp/abc && touch /tmp/abc/hehe
```

范例二：测试 /tmp/abc 是否存在，若不存在则予以建立，若存在就不做任何事情

```shell
$ ls /tmp/abc || mkdir /tmp/abc
```

:star: 范例三：我不清楚 /tmp/abc 是否存在，但就是要建立 /tmp/abc/hehe 文件

```shell
$ ls /tmp/abc || mkdir /tmp/abc && touch /tmp/abc/hehe
```

:star: 例题：以 ls 测试 /tmp/vbirding 是否存在，如果存在则显示“exist”，如果不存在，则显示“not exist"

```shell
$ ls /tmp/vbirding && echo "exist" || echo "not exist"
```

由于指令是一个接着一个去执行的，因此，如果真要使用判断，那么这个&& 与 || 的顺序就不能搞错。一般来说，假设判断式有三个，也就是：

 command1 && command2 || command3

而且顺序通常不会变，因为一般来说，command2 与 command3 会放置肯定可以执行成功的指令。

#### 10.6 管道命令（pipe）

管道命令使用的是| 这个定界符。另外，管道命令与连续下达命令是不一样的。

假设我们想要知道/etc/  底下有多少文件，那么可以利用ls /etc 来查询。不过，因为/etc 底下的文件太多，导致一口气就将屏幕塞满了，不知道前面输出的内容是啥。此时，我们可以通过less 指令的协助。

```shell
ls -al /etc | less
```

这个管道命令 |  仅能处理经由前一个指令传来的正确信息，也就是standard output 的信息，对于standard error 并没有直接处理的能力。

在每个管道后面接的第一个数据必定是指令，而且这个指定必须要能够接受 standard input的数据才行，这样的指令才可以是为管道命令。例如less, more, head, tail 等。ls,cp, mv 就不是管道命令了。

* 管道命令仅会处理 standard output，对于 standard error output 会忽略不计
* 管道命令必须要能够接受来自前一个指令的数据成为standard input 继续处理才行


> __思考：如果硬要让 standard error 可以被管道命令所使用，那么该如何处理？__

> 通过资料流重导向即可， 让 2>&1 加入指令中 就可以让 2> 变成 1>了
>
> ---

##### 10.6.1 截取命令：cut，grep

截取命令就是将一段数据经过分析后，取出我们想要的。或者是经由分析关键字，取得我们所想要的那一行。一般来说，截取数据通常是针对“一行一行”来分析的，并不是整篇信息分析的

###### cut

这个指令可以将一段信息的某一段切出来，处理的信息是以行为单位。

```shell
$ cut -d '分隔字符' -f fields  # 用于有特定分隔字符
$ cut -c 字符区间
选项与参数：
-d：后面接分隔字符，与-f 一起使用
-f：依据 -d 的分隔字符将一段信息分隔成为数段， 用 -f 取出第几段的意思
-c：以字符的单位取出固定字符区间
```

范例一：将PATH变量取出，并找出第五个路径

echo ${PATH} | cut -d ':' -f 5

如果想要列出第三个与第五个：

echo ${PATH} | cut -d ':' -f 3,5

范例二：将export输出的信息，取得第12 个字符以后所有字符串

export | cut -c 12-

-c 可以处理比较有格式的输出信息

我们还可以指定某个范围的值，例如12-20的字符，就是cut -c 12-20

范例三：用last将显示的登入者信息中，仅留下使用者大名

last | cut -d ' ' -f 1

cut主要的用途在于将同一行里面的数据进行分解， 最常使用在分析一些数据或文字资料的时候。这是因为有时候我们会以某些字符当做分割的参数，然后将数据加以切割，以取得我们所需要的数据。不过，cut在处理多空格相连的数据时，可能会比较吃力，所以某些时候可能会用awk来取代

###### grep

cut是将一行信息中，取出某部分我们想要的，

grep是分析一行信息，如果其中有我们所需要的，就将该行取出来

```shell
$ grep [-acinv] '搜索字符串' filename
#选项与参数：
-a：将binary 文件以text 文件的形式搜索信息
-c：计算找到'搜索字符串'的次数
-i：忽略大小写的不同，所以大小写视为相同
-n：顺便输出行号
-v：反向选择，亦即显示出没有'搜索字符串'内容的那一行
--color=auto：可以将找到的关键字部分加上颜色的显示
```

范例一：将last 中，有出现root的那一行就取出来

```shell
$ last | grep 'root'
```

范例二：与范例一相反，只要没有root的就取出

```shell
$ last | grep -v 'root'
```

范例三：在last 的输出信息中，只要有root就取出，并且仅取第一栏

```shell
$ last | grep 'root' | cut -d ' ' -f 1
```

范例四：取出 /etc/man_db.conf 内含 MANPATH 的那几行

```shell
$ cat /etc/man_db.conf | grep 'MANPATH'
```

> 书上给的答案是：
>
> ```shell
> $ grep --color=auto 'MANPATH' /etc/man_db.conf
> ```

grep 用在正则表示法里，能够处理的资料实在是多得很，grep可以解析一行文字，取得关键字，若该行有存在关键字，就会整行列出来。CentOS 7中，默认的grep已经主动加上--color=auto在alias内了。

<<<<<<< HEAD
<<<<<<< HEAD
##### 10.6.2 排序命令：sort，wc，uniq

##### wc

​:star: 范例二：我知道使用 last 可以输出登录者，但是last 最后两行并非帐号内容，那么请问，我该如何以一行指令串取得登录系统的总人次？

```shell
$ last | wc -l
```

> __书上给的答案是__
>
> ```shell
> $ last | grep [a-zA-Z] | grep -v 'wtmp' | grep -v 'reboot' | grep -v 'unknown' | wc -l
> #由于 last 会输出空白行，wtmp，unknown，reboot等无关帐号登录的信息，因
> #此，我利用grep 取出非空白行，以及去除上述关键字那几行，再计算行数。
> ```

当你要知道目前你的帐号文件中有多少个帐号时，就使用这个方法：cat /etc/passwd | wc -l 。如果要计算一个文件里头一共有多少个字符时，就使用wc -m 

----

#### 10.6.3 双向重导向：tee

tee会同时将数据流分送到文件与屏幕中去，而输出到屏幕的，其实就是stdout，那就可以让下个指令继续处理

```shell
$ tee [-a] file
-a:以累加（append）的方式，将数据加入file 中

$ last | tee last.list | cut -d ' ' -f1
#这个范例可以让我们将last 的输出存一份到 last.list 文件中

$ ls -l /home | tee ~/homefile | more
#这个范例是将 ls 的数据存一份到 ~/homefile，同时屏幕也有输出信息

$ lst -l / | tee -a ~/homefile | more
#要注意，tee 后接的文件会被覆盖，若加上-a则能将信息累加
```

tee 可以让stdout转存一份到文件内并将同样的数据继续送到屏幕去处理，这样除了可以让我们同时分析一份数据并记录下来之外，还可以作为处理一份数据的中间暂存文件记录之用。

----

#### 10.6.4 字符转换命令：tr,col,join,paste,expand

##### tr

tr可以用来删除一段信息当中的文字，或者是进行文字信息的替换

```shell
$ tr [-ds] SET1 ...
选项与参数：
-d：删除信息当中的 SET1 这个字符串
-s：取代掉重复的字符
```

​:star: 范例一：将 last 输出的信息中，所有的小写变成大写字符

```shell
$ last | tr '[a-z]' '[A-Z]'
#不加单引号也是可以执行的： last | tr [a-z] [A-Z]
```

范例二：将 /etc/passwd 输出的信息中，将冒号删除

```shell
$ cat /etc/passwd | tr -d ':'
```

​:star: 范例三：将 /etc/passwd 转存成 dos 断行到 /root/passwd 中，再将^M符号删除

```shell
~~$ cat /etc/passwd | unix2dos | tr -d '^M'~~
```

__正确答案是__

```shell
$ cp /etc/passwd ~/passwd && unix2dos ~/passwd
$ file /etc/passwd ~/passwd
$ cat ~/passwd | tr -d '\r' > ~/passwd.linux
$ ll /etc/passwd ~/passwd*
# file 命令查看 /etc/passwd 和 ~/passwd 的编码方式
# \r 指的是 DOS 的断行字符
# 处理过后确认下转成DOS 格式的文档和Linux格式的 大小一致
```

这个指令也可以写在正则表达式里，因为他也是由正则表达式的方式来取代数据的。也常常用来取代文件中的怪异符号。

----

##### col

```shell
$ col [-xb]
-x：将tab 键转换成对等的空白键
```

​:star: 范例一：利用 cat -A 显示出所有特殊按键，最后以 col 将 [tab] 转成空白（以/etc/man_db.conf文件为例）

```shell
$ cat -A /etc/man_db.conf # 此时会看到很多^I的符号，那就是tab
$ cat /etc/man_db.conf | col -x | cat -A | more
```

col 可以用来简单地处理将tab键取代为空白键。

----

##### join

在处理两个文件之间的数据，而且，主要是在处理__两个文件中，有相同资料的那一行，才将它加在一起__ 

```shell
$ join [-ti12] file1 file2
选项与参数：
-t：join默认以空白字符分割数据，并且比对第一个字段的数据，如果两个文件相同，则将两笔数据连成一行，且第一个字段放在第一个
-i：忽略大小写
-1：这个是数字的1，代表第一个文件要用哪个字段来分析的意思
-2: 代表第二个文件要用哪个字段来分析的意思
```

​:star: 范例一：用root的身份，将 /etc/passwd 与 /etc/shadow 相关的数据整合成一栏

```shell
> ~~$ join -t /etc/passwd /etc/shadow~~
```

__正确答案__

```shell
$ join -t ':' /etc/passwd /etc/shadow 
```

> 这个主要是应用-t 这个参数，而且感觉应用范围比较狭窄，只有在第一列相同的时候才用的到

范例二： 我们知道 /etc/passwd 第四列是GID，那个 GID记录在 /etc/group当中的第三列，请问如何将两个文件整合：

```shell
$ join -t ':' -1 4 -2 3 /etc/passwd /etc/group
```

__正确答案__

```shell
$ join -t ':' -1 4 /etc/passwd -2 3 /etc/group
```

> 这个要注意的是 第一个文件指定完字段后 要紧接着写上文件名
>
> 而且，相同的字段的部分被移动到最前面，第二个文件相同部分就不显示了

join在处理两个相关的数据文件时，很有帮助。

在使用join 之前，需要处理的文件应该要先经过sort 处理，否则有些比对项目会被略过

----

##### paste

相对于join必须要比对两个文件的数据相关性，paste就直接将两行帖在一起，且中间以tab隔开

```shell
$ paste [-d] file1 file2 ...
选项与参数：
-d：后面可以接分割字符，默认是以tab来分割的
-：如果file 部分写成 -， 表示来自是stdinput 的数据的意思
```

范例一：用root身份，将 /etc/passwd 与 /etc/shadow 同一行贴在一起

```shell
$ paste -d ':' /etc/passwd /etc/shadow
```

范例二：先将 /etc/group 读出（用cat），然后与范例一贴上一起，且仅取出前三行

```shell
$ paste /etc/passwd /etc/shadow | paste - /etc/group | head -n 3
```

书上给的答案是：

```shell
$ cat /etc/group | paste /etc/passwd /etc/shadow - | head -n 3
```

----

##### expand

这个就是将[tab] 按键转成空白键

```shell
$ expand [-t] file
-t:后面可以接数字。一般来说，一个tab键可以用8个空白键取代。我们也可以自行定义个tab键代表多少个字符
```

范例一：将 /etc/man_db.conf 内行首为 MANPATH的字样取出，仅取前三行

```shell
$ grep 'MANPATH' 
```

__正确答案是：__

```shell
$ grep '^MANPATH' /etc/man_db.conf | head -n 3
```

范例二：承上，如果我想要将所有的符号都列出来（用cat）

```shell
$ grep '^MANPATH' /etc/man_db.conf | head -n 3 | cat -A
```

​:star: 范例三：承上，我将[tab]键设定为6个字符

```shell
$ grep 'MANPATH' /etc/man_db.conf | head -n 3 | expand -t 6 - | cat -A
```

因为[tab]最大的功能就是格式排列整齐，我们转成空白键后，这个空白键也会依据我们自己的定义来增加大小，所以，并不是一个^I就会换成8个空白。

----

##### 10.6.5 分割命令：split

可以将一个大文件，依据文件大小或行数来分割，可以将大文件分割成小文件。

```shell
$ split [-bl] file PREFIX
选项与参数：
-b：后面可接想要分割成的文件大小，可加单位，例如 b, k, m 等
-l：以行数来分割
PREFIX: 代表前置字元的意思，可作为分割文件的前导文字
```

范例一：我的/etc/services 有600+k，若想要分成300k 一个文件时？

```shell
$ split -b 300k /etc/services
```

__更正确的写法是__:

```shell
$ cd /tmp; split -b 300k /etc/services services
```

__要注意前导文字的书写，关系到分割文件的文件名__

​:star::star: 范例二：如何将上面的三个小文件合成一个文件，文件名为serviceback

```shell
$ 
```

__正确答案：使用资料流重导向__

```shell
$ cat services* >> servicesback
```

范例三：使用ls -al / 输出的信息中，每10行记录成一个文件

```shell
$ ls -al / | split -l 10 - lsroot
```

__最好是再加一句__

```shell
$ wc -l lsroot*
```

在Linux下要将文件分割的话，那么就用-b size 来将一个分割的文件限制其大小，如果是行数的话，那么就使用-l line 来分割，如此一来，你就可以轻易的将你的文件分割策划那个某些软件能够支持的最大容量了

----

##### 10.6.6 参数代换：xargs

这个就是在产生某个指令的参数的意思，xargs可以读入stdin 的数据，并且以空白字符或断行字符作为分辨，将stdin的数据分隔成为arguments。因为是以空白字符作为分隔，所以，如果有一些文件名或者是其他意义的名词内含有空白字符的时候iou，xargs可能就会误判了。

```shell
$ xargs [-0epn] command
-0:如果输入的stdin含有特殊字符，例如`,\,空白键等字符时，这个 -0 参数可以将它还原成一般字符，这个参数可用于特殊状态
-e：这个是EOF的意思。后面可以接一个字符串，当xargs分析到这个字符串时候，就会停止继续工作
-p：在执行每个指令的argument时，都会询问使用者的意思
-n：后面接次数，每次command指令执行时，要使用几个参数的意思
当xargs后面没有接任何的指令时，默认是以echo来进行输入的
```

范例一：将/etc/passwd 内的第一栏取出，仅取三行，使用id这个指令将每个帐号内容秀出来

*错误的示范*：

```shell
$ id $(cut -d ':' -f1 /etc/passwd | head -n 3)
# 虽然使用 $(cmd) 可以预先取得参数，但是id这个指令仅能接受一个参数
```

```shell
$ cut -d ':' -f 1 /etc/passwd | head -n 3 | id
# 因为id并不是管道命令因此在上面这个指令执行后，前面的东西统统不见，只会执行id
```

```shell
$ cut -d ':' -f 1 /etc/passwd | head -n 3 | xargs id
#依旧会出现错误，这是因为xargs一口气将全部的数据通通丢给id处理，但id就接受1个最多
```

正确的做法：

```shell
$ cut -d ':' -f 1 /etc/passwd | head -n 3 | xargs -n 1 id
#通过-n来处理，一次给予一个参数，因此上述结果就是正确的
```

范例二：同上，但是每次执行id时，都询问使用者是否动作

```shell
$ cut -d ':' -f 1 /etc/passwd | head -n 3 | xargs -n 1 -p id
```

范例三：将所有的 /etc/passwd 内的帐号都以 id 查询，但查到 sync 就结束指令串

```shell
$ cut -d ':' -f 1 /etc/passwd | xargs -n 1  -e 'sync' id
```

__正确的写法__

```shell
$ cut -d ':' -f 1 /etc/passwd | xargs -e'sync' -n 1 id
```

> 重点是在于-e和后面的字符串是连在一起的，中间没有空白键，如果加上空白键就会报错。

使用xargs的原因是，很多指令其实并不支持管道命令，因此我们可以通过xargs来提供该指令引用standard input 之用。举例来说

范例四：找出 /usr/sbin 底下具有特殊权限的文件名，并使用 ls -l 列出详细属性

```shell
$ find /usr/sbin -perm /7000 | xargs ls -l
或者
$ ls l-l $(find /usr/sbin -perm /7000)
```

----

##### 10.6.7 关于减号 -的用途

管道命令在bash的连续的处理进程中是相当重要的，另外，在log file的分析中也是相当重要的一环，

```shell
$ mkdir /tmp/homeback
$ tar -cvf - /home | tar -xvf - -C /tmp/homeback
```

意思是：将/home 打包，但打包的数据不是记录到文件，而是传送到stdout，经过管道后，将tar -cvf - /home 传送给后面的 tar -xvf  - 。后面的这个-是取前一个指令的stdout，因此，我们就不需要使用filename了。







China Hub inventory, Apr,23th, 2018











































=======
----

#### 10.6.2 排序命令：sort, wc, uniq
=======
##### 10.6.2 排序命令：sort, wc, uniq
>>>>>>> bd5be6228affdd148a87447167e028d83615a183

举例来说，使用last可以查得系统上面有登入主机者的身份，那么我们可以针对每个使用者查出 他们的总登入次数吗。

###### sort

sort可以依据不同的数据类型来排序，例如数字与文字的排序就不一样。此外，排序的字符与语系的编码有关，因此，当需要排序时，建议使用 LANG=C 来让语系统一，数据排序比较好些

```shell
$ sort [-fbMnrtuk] [file or stdin]
选项与参数：
-f:忽略大小写的差异，例如A与a视为编码相同
-b：忽略最前面的空白字符部分
-M：以月份的名字来排序，例如 JAN，DEC等等的排序方法
-n：使用[纯数字]进行排序（默认是以文字形态来排序的）
-r：反向排序
-u：就是 uniq，相同的资料中，仅出现一行代表
-t：分隔符号，默认是用tab来分隔
-k：以哪个区间来进行排序的意思
```

范例一：个人账号都记录在 /etc/passwd下，请将账号进行排序

```shell
$ cat /etc/passwd | sort
```

​:star: 范例二：/etc/passwd 内容是以： 来分隔的，我想以第三栏含后面数据来排序，该如何？

```shell
$ cat /etc/passwd | sort -t ':' -k 3
```

如果单纯以第三列来处理排序则是：

```shell
$ cat /etc/passwd | sort -t ':' -k 3,3
```

__但这是按字符顺序来排列的，不是按数字顺序排列的，所以才会发现数字不是从小到大__

所以和自己的想象还有一点点差距，那怎么办呢？

单纯以第三列按照数字顺序排序：

```shell
$ cat /etc/passwd | sort -t ':' -k 3,3 -n
```

​:star: 范例三：利用last，将输出的数据仅取账号，并加以排序(这个是与cut结合的例子，不错)

```shell
$ last | cut -d ' ' -f 1 | sort -u
```

###### uniq

如果我排序完成了，想要将重复的数据仅列出一个显示，可以怎么做：

```shell
$ uniq [-ic]
选项与参数：
-i:忽略大小写字符的不同
-c：进行计数
```

范例一：使用last将账号列出，仅取出账号栏，进行排序后仅取出一位：

```shell
$ last | cut -d ' ' f1 | sort | uniq
```

​:star: 范例二：如果还想知道每个人的登入总次数：

```shell
$ last | cut -d ' ' -f1 | sort | uniq -c
```

wtmp与第一行的空白都是last的默认字符，可以忽略

由于这个指令是在将重复的东西减少，所以当然要配合排序过的文件来处理

###### wc

wc可以帮我们计算出输出的信息的整体数据

```shell
$ wc [-lwm]
选项与参数：
-l:仅列出行
-w：仅列出多少字（英文单字）
-m：多少字符
```

范例一：那个/etc/man_db.conf 里面到底有多少相关字、行、字元数？

```shell
$ wc -wlm /etc/man_db.conf
```

> 书上给的答案是 ： cat /etc/man_db.conf | wc



<<<<<<< HEAD
#### 10.5 数据流重导向

----

数据流重导向就是将某个指令执行后应该要出现在屏幕上的数据，给传输到到其他地方，例如文件或者是设备（例如打印机之类），这个东西在Linux的文字模式下很重要，尤其是如果我们想要将某些数据存储下来时

##### 10.5.1 什么是数据流重导向

我们执行一个指令的时候，这个指令可能会由文件读入数据，经过处理之后，再将数据输出到屏幕上。标准输出与标准错误输出默认都是输出到屏幕上面来的

标准输出指的是”指令执行所回传的正确的信息“，标准错误可以理解为”指令执行失败后，所回传的错误信息“。比如，我们系统默认有  /etc/crontab 但却没有 /etc/vbirdsay， 此时若下达 cat /etc/crontab /etc/vbridsay 这个指令时，cat会进行：

标准输出：读取 /etc/crontab 后，将该文件内容显示到屏幕上

标准错误输出：因为无法找到 /etc/vbirdsay， 因此在屏幕上显示错误讯息

不管正确或错误的数据都是默认输出到屏幕上，所以屏幕是乱乱的。

标准输入：代码为0，使用< 或 <<

标准输出：代码为1，使用 > 或 >>

标准错误输出：代码为2，使用 2> 或 2>>

范例一：观察你的系统根目录（/）下各目录的文件名、权限与属性，并记录下来

```shell
$ ll /  #此时屏幕会显示出文件名
$ ll / > ~/rootfile #屏幕并无任何信息
$ ll ~/rootfile # 有个新文件被建立了
```

如果再次下达 ll /home > ~/rootfile，它将变成仅有 ll /home 的资料，而原本的ll / 就没有了

因为该文件的建立方式是：

1. 该文件（本例中是~/rootfile)若不存在，系统会自动的将他建立起来，但是
2. 当这个文件存在的时候，那么系统就会先将这个文件内容清空，然后再将数据写入
3. 也就是如果以>输出到一个已存在的文件中，那个文件会被覆盖掉

如果想要将数据累加而不将旧的数据删除，那么就利用两个大于符号就好了。以上面的范例阿狸说，应该要改成 ll / >> ~/rootfile 即可。

范例二：利用一般身份账号搜寻 /home 底下是否有名为 .bashrc 的文件存在

```shell
$ find /home -name .bashrc
find: ;;;;;;
```

由于/home 底下还有我们之前建立的账号存在，所以不可以都看到。所以就会有错误及正确资料了。假如我想要将数据输出到list这个文件中呢，执行 find /home -name .bashrc > list, 会发现list里面仅仅存储了正确输出信息，至于屏幕上还是会有错误的信息出现。如果要将正确与错误的信息分别存入不同的文件中需要怎么做？

​:star: 范例三：承范例二，将stdout 与stderr 分别存到不同文件中去

```shell
$ find /home -name .bashrc > list_right 2> list_error
```

##### /dev/null 垃圾桶黑洞设备与特殊写法

如果我知道错误信息会发生，所以要将错误信息忽略掉而不显示或储存呢，这时候黑洞装置 /dev/null 就很重要了，这个/dev/null 可以吃掉任何导向这个设备的信息

范例四：承接范例三，将错误的信息丢弃，屏幕上显示正确的资料

```shell
$ find /home -name .bashrc 2> /dev/null  #只有stdout 会显示到屏幕上，stderr被丢弃了
```

再想想一下，如果我要将正确与错误信息通通写入同一个文件去呢，这个时候就要使用特殊的写法了

​:star: 范例五：将指令的资料全部写入名为list 的文件中

```shell
$ find /home -name .bashrc > list 2> list #这是错误的写法
$ find /home -name .bashrc > list 2>&1   #正确的写法
$ find /home -name .bashrc &> list   # 正确的写法
```

第一行错误的原因是：__由于两股数据同时写入一个文件，有没有使用特殊的语法，此时两股数据可能会交叉写入该文件内，造成次序的错乱__, 所以虽然最终list文件还是会产生，但是里面的数据排列就会怪怪的，而不是原本屏幕上的输出排序

##### standard input：< 与 <<

范例六：利用cat 指令来建立一个文件的简单流程

```shell
$ cat > catfile
testing
cat file test
<== 这里按下ctrl+d来离开
```

由于加入> 在cat后，所以那个catfile会被主动的建立，而内容就是刚刚键盘输入的那两行资料

范例七：用stdin 取代键盘的输入以建立新文件的简单流程

```shell
$ cat > catfile < ~/.bashrc
$ ll catfile ~/.bashrc
```

<<代表结束的输入字符的意思，举例：我要用cat 直接将输入的信息输出到catfile中，且当由键盘输入eof时，该次输入就结束。

```shell
$ cat > catfile << "eof"
> this is a test.
> ok now stop
> eof
```

利用<< 右侧的字符，我们可以终止一次输入，而不必输入[ctrl]+d来结束。

为什么要使用命令输出重导向：

* 屏幕输出的信息很重要，而且我们需要将他存下来的时候
* 背景执行中的程序，不希望他干扰屏幕正常的输出结果时
* 一些系统的例行命令（例如写在/etc/crontab 中的文件）的执行结果，希望他可以存下来时
* 一些执行命令的可能已知错误讯息时，想以 2> /dev/null 将他丢掉时
* 错误信息与正确信息需要分开输出时

问，假设我要将 echo "error message" 以standard error output 的格式来输出，该如何处置？

答：既然有 2>&1 来将 2>转到 1>去，那应该也会有 1>&2吧

```shell
$ echo "error message" 1>&2
$ echo "error message" 2> /dev/null 1>&2
```

结果是第一条有信息输出到屏幕上，第二条没有信息，这表示该信息已经通过2> /dev/null 丢到垃圾桶去了，可以肯定是错误讯息

##### 10.5.2 命令执行的判断依据：;,&&,||

----

$?(指令回传值) 与 && 或 ||

__如果前一个指令执行的结果为正确，在Linux下会回传一个$?=0的值__

| 指令下达情况         |                 说明                 |
| :------------- | :--------------------------------: |
| cmd1 && cmd2   | 1. 若cmd1执行完毕且正确执行（$?=0）,则开始执行cmd2  |
|                |  2. 若cmd1执行完毕且为错误（$?!=0）,则cmd2不执行  |
| cmd1 \|\| cmd2 | 1. 若cmd1 执行完毕且正确执行（$?=0），则cmd2 不执行 |
|                |  2. 若cmd1执行完且为错误（$?!=0）,则开始执行cmd2  |

范例一：使用ls 查阅目录 /tmp/abc 是否存在，若存在则用 touch 建立 /tmp/abc/hehe

```shell
$ ls /tmp/abc && touch /tmp/abc/hehe
```

范例二：测试 /tmp/abc 是否存在，若不存在则予以建立，若存在就不做任何事情

```shell
$ ls /tmp/abc || mkdir /tmp/abc
```

​:star: 范例三：我不清楚 /tmp/abc 是否存在，但就是要建立 /tmp/abc/hehe 文件

```shell
$ ls /tmp/abc || mkdir /tmp/abc && touch /tmp/abc/hehe
```

​:star: 例题：以 ls 测试 /tmp/vbirding 是否存在，如果存在则显示“exist”，如果不存在，则显示“not exist"

```shell
$ ls /tmp/vbirding && echo "exist" || echo "not exist"
```

由于指令是一个接着一个去执行的，因此，如果真要使用判断，那么这个&& 与 || 的顺序就不能搞错。一般来说，假设判断式有三个，也就是：

 command1 && command2 || command3

而且顺序通常不会变，因为一般来说，command2 与 command3 会放置肯定可以执行成功的指令。
>>>>>>> 6cf4700bcc157758e141112ccaad6f0e8a92457e









=======
>>>>>>> bd5be6228affdd148a87447167e028d83615a183





























